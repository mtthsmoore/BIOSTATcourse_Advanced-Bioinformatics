{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdgroeve/D012513A-Specialised-Bio-informatics/blob/master/Inferential%20statistics%20I/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHOPfvAKI66I"
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(123)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg6XIrxWOZBw"
      },
      "source": [
        "# Inferential statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YhjhJPTPD0X"
      },
      "source": [
        "\n",
        "In inferential statistics we again make inferences about a population given one or more samples. However, this time we make a **claim** about the population and use the sample(s) to estimate the likelihood of this claim by making assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE-fst-WI66N"
      },
      "source": [
        "## The one sample t-test\n",
        "\n",
        "To explain this further, consider a lab where protein mixtures with known concentration for each protein are produced by a highly sensitive machine. Each day the machine is tested by sampling $n$ mixtures and measuring their protein concentrations. \n",
        "\n",
        "We focus on one protein \"proteinA\". To accomodate the mixture standards, the mean proteinA concentration should be 0.3 with a variance between the mixtures $< 0.01$.\n",
        "\n",
        "Before we continue we make the following **assumptions**:\n",
        "\n",
        "- the proteinA concentration follows a normal distribution\n",
        "- the mixtures are drawn independently (this is of course not an assumption as we sampled the mixtures ourselves)\n",
        "\n",
        "Let's say our machine is working properly. We draw $n=9$ mixtures at random from a day's batch of a perfectly working machine and measure the proteinA concentration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erJf3Ln2I66N"
      },
      "source": [
        "n=9\n",
        "#loc = mean, scale = standard deviation\n",
        "x = np.random.normal(size=n,loc=0.3,scale=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfTBseChI66P"
      },
      "source": [
        "We make the following claim: the mean proteinA concentration $\\mu$ of the population from which $x$ is drawn is $\\mu_0 = 0.3$. \n",
        "\n",
        "To investigate this we compute the difference $D_{observed}$ between our sample's mean $\\overline{x}$ and the claimed population mean $\\mu_0 = 0.3$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXKQx5RFI66Q"
      },
      "source": [
        "mu0 = 0.3\n",
        "D_observed = np.mean(x)-mu0\n",
        "print(\"observed mean difference: %f\"%D_observed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtzGwq9sI66S"
      },
      "source": [
        "Is $D_{observed}$ **significant**? Should we conclude that something is wrong with the machine and stop it?\n",
        "\n",
        "We know that our proteinA concentration population has indeed $\\mu=0.3$ (again, in reality we don't have access to this information, we try to infer it from the sample).\n",
        "\n",
        "Next we simulate drawing many ($m=100000$) samples $x$ with $n=9$ from this population. For each sample we compute the difference $D$ between the sample mean $\\overline{x}$ and $\\mu_0$\n",
        "\n",
        "$$D = \\overline{x}-\\mu_0,$$\n",
        "\n",
        "and plot the distribution of these differences $D$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPChMJ8LI66S"
      },
      "source": [
        "m = 100000\n",
        "mean_diffs = []\n",
        "for i in range(m):\n",
        "    x_tmp = np.random.normal(size=n,loc=0.3,scale=0.05)\n",
        "    D = np.mean(x_tmp)-mu0\n",
        "    mean_diffs.append(D)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.distplot(mean_diffs,color=\"b\",kde=False)\n",
        "plt.xlabel(\"D\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdP9gaII66W"
      },
      "source": [
        "Again, we know all the samples were drawn from a population with $\\mu=\\mu_0=0.3$. So, **none of the differences $D$ we observe in the above distribution are significant**. The distribution of all the differences $D$ is called the **null distribution** for the one sample t-test.\n",
        "\n",
        "It is important to note that the shape of the null distribution depends strongly on the sample size $n$ and the variance $\\sigma$ of the population from which the samples were drawn (so not on the actual value of $\\mu$ itself). To illustrate this for the variance of the population we draw samples with $n=9$ from populations with an increasing variance and compute null distributions as we did before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtXLnSEhI66X"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for sigma_new in [0.01,0.03,0.06]:\n",
        "    mean_diffs = []\n",
        "    for i in range(m):\n",
        "        x_tmp = np.random.normal(size=n,loc=0.3,scale=sigma_new)\n",
        "        D = np.mean(x_tmp)-mu0\n",
        "        mean_diffs.append(D)\n",
        "    sns.distplot(mean_diffs,label=\"std=%f\"%sigma_new)\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO4kKnO-U4N0"
      },
      "source": [
        "Again, none of these differences are significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idWkhA6_I66a"
      },
      "source": [
        "Similarly for the sample size $n$, we fix the population variance and compute null distributions for different values of $n$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXBkFDwoI66a"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for n in [3,6,9,12,18]:\n",
        "    mean_diffs = []\n",
        "    for i in range(m):\n",
        "        x_tmp = np.random.normal(size=n,loc=0.3,scale=0.05)\n",
        "        D = np.mean(x_tmp)-mu0\n",
        "        mean_diffs.append(D)\n",
        "    sns.distplot(mean_diffs,label=\"n=%i\"%n)\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DycgYyQ6I66d"
      },
      "source": [
        "We observe that these shapes clearly differ. \n",
        "\n",
        "In hypothesis testing the dependency of the shape of the null distribution on the variance $\\sigma$ of the population from which $x$ is drawn disappears by replacing $D$ with what is know as the **T-statistic**: \n",
        "\n",
        "$$T = \\frac{\\overline{x}-\\mu}{s_{n-1}^2 / \\sqrt{n}},$$\n",
        "\n",
        "which follows a null distribution called the Student’s t-distribution with $n-1$ degrees of freedom. We can see that the T-statistic is very simmilar to the difference $D$, except for the normalization term $\\frac{s_{n-1}^2}{\\sqrt{n}}$. \n",
        "\n",
        "To illustrate this we draw samples with $n=9$ from populations with an increasing variance and plot a null distribution of the T-statistic for each of the populations (similarly as was done above):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSSNsHBI66d"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for sigma_new in [0.01,0.03,0.06]:\n",
        "    mean_diffs = []\n",
        "    for i in range(m):\n",
        "        x_tmp = np.random.normal(size=n,loc=0.3,scale=0.05)\n",
        "        T = (np.mean(x_tmp)-mu0) / (np.std(x_tmp)/np.sqrt(n))\n",
        "        mean_diffs.append(T)\n",
        "    sns.distplot(mean_diffs,label=\"std=%f\"%sigma_new)\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNjnrBDvI66f"
      },
      "source": [
        "We see that the null distributions now all have the same shape. \n",
        "\n",
        "The dependency of the shape of the null distribution on the sample size $n$ is taken into account by the degrees of freedom (by choosing the Student’s t-distribution that corresponds to a sample size of $n-1$). \n",
        "\n",
        "From the Student’s t-distribution with $n-1$ degrees of freedom the probability of observing $\\mu_0$ or a more extreme T-statistic is computed. This probability is called the **p-value**. \n",
        "\n",
        "Finally the p-value is compared against the **significance level** $\\alpha$.\n",
        "\n",
        "If the probability of observing $\\mu_0$ under the null distribution (the p-value) is equal or smaller than $\\alpha$ then we call this difference significant and conclude that the sample is not drawn from a population with mean $\\mu=\\mu_0$.\n",
        "\n",
        "We have just performed a one sample t-test. This hypothesis test claims that the mean of a population $\\mu$ from which a sample is drawn is equal to some value $\\mu_0$. \n",
        "\n",
        "As with all hypothesis testing there are two hypothesis:\n",
        "\n",
        "- The null hypothesis ($H_0$) states that $\\mu=\\mu_0$.\n",
        "- The two-tailed hypothesis ($H_1$) states that $\\mu \\ne \\mu_0$.\n",
        "\n",
        "There are also two possible one-tailed hypothesis:\n",
        "\n",
        "- The upper-tailed hypothesis ($H_1$) states that $\\mu > \\mu_0$.\n",
        "- The lower-tailed hypothesis ($H_1$) states that $\\mu < \\mu_0$.\n",
        "\n",
        "If the computed p-value is equal to or smaller than the significance level $\\alpha$ we reject $H_0$ and accept $H_1$.\n",
        "\n",
        "We can simply perform a one sample t-test as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSutP-PcI66f"
      },
      "source": [
        "import scipy.stats as stats\n",
        "stats.ttest_1samp(np.array(x),mu0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSZt4u6zI66h"
      },
      "source": [
        "Given this p-value we accept $H_0$ at $\\alpha$=0.01.\n",
        "\n",
        "Now, suppose we draw a sample of the protein mixtures on another day:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkmf5YNI66i"
      },
      "source": [
        "x_bad = np.random.normal(size=n,loc=0.37,scale=0.05)\n",
        "print(\"Mean bad sample: %f\"%np.mean(x_bad))\n",
        "stats.ttest_1samp(np.array(x_bad), mu0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgLA7yKwI66k"
      },
      "source": [
        "This time the p-value is much lower and more than low enough ($\\alpha=0.01$) to conclude that the mean proteinA concentration in the mixtures is not 0.3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kepAy5CDXRyO"
      },
      "source": [
        "## The (unpaired) two sample t-test for equal means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uq8SZbI66k"
      },
      "source": [
        "The unpaired two sample t-test for equal means is a hypothesis test that claims that the means of two samples $x_1$ with sample size $n_1$ and $x_2$ with sample size $n_2$ are equal. It makes the following assumptions:\n",
        "\n",
        "- both samples are drawn from a normal distribution\n",
        "- both samples are drawn from populations with equal variance\n",
        "- the samples should be drawn independently\n",
        "\n",
        "Again we define two hypothesis:\n",
        "\n",
        "- The null hypothesis $H_0$ states that $\\overline{x}_1 = \\overline{x}_2$.\n",
        "- The two-tailed alternative hypothesis $H_1$ states that $\\overline{x}_1 \\ne \\overline{x}_2$.\n",
        "\n",
        "The T-statistic that is used to test the null hypothesis is:\n",
        "\n",
        "$$T = \\frac{\\overline{x}_1 - \\overline{x}_2}{SE(\\overline{x}_1 - \\overline{x}_2)}$$\n",
        "\n",
        "where the denominator is the standard error of the difference between the means. It is computed as \n",
        "\n",
        "$$SE(\\overline{x}_1 - \\overline{x}_2) = s_p \\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}$$\n",
        "\n",
        "where $s_p$ is the pooled variance of both samples and is computed as\n",
        "\n",
        "$$s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 +n_2 -2}}$$\n",
        "\n",
        "where $s_1$ and $s_2$ are the standard deviations of samples $x_1$ and $x_2$ respectively. This T-statistic follows a Student’s t-distribution with $n_1+n_2-2$ degrees of freedom.\n",
        "\n",
        "Now what does this mean? To explain this we should understand the unpaired two sample t-test for equal means as a test to determine whether two independent samples with equal variance were drawn from populations having the same normal distribution. \n",
        "\n",
        "\n",
        "To illustrate we again assume we know the full population.\n",
        "\n",
        "First we compute a null distribution for the difference $D$ between the means (so without the standard error in the denominator), i.e.\n",
        "\n",
        "$D=\\overline{x}_1-\\overline{x}_2.$\n",
        "\n",
        "We do this by repeatedly drawing $m$ times two samples with $n_1=n_2=9$ from the same population and computing $D$ for each of the two samples: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lcmE_YI66k"
      },
      "source": [
        "n = 9\n",
        "null_distribution = []\n",
        "for i in range(m):\n",
        "    x1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    x2 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    D = (np.mean(x1)-np.mean(x2))\n",
        "    null_distribution.append(D)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.distplot(np.array(null_distribution),color=\"g\")\n",
        "plt.xlabel(\"D\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K6G4JakI66o"
      },
      "source": [
        "Again, even though both samples are drawn from the same population they do show differences in mean that we know are not significant.\n",
        "\n",
        "Just as with the one sample t-test the shape of this distribution depends on the variance of the population from which the samples are drawn. We can see this by plotting null distributions for $D$ by sampling from populations with an increasing variance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHAOEeghI66o"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for sigma_gene_new in [0.01,0.03,0.06]:\n",
        "    null_distribution_new = []\n",
        "    for i in range(m):\n",
        "        x1 = np.random.normal(size=n,loc=0.26,scale=sigma_gene_new)\n",
        "        x2 = np.random.normal(size=n,loc=0.26,scale=sigma_gene_new)\n",
        "        D = (np.mean(x1)-np.mean(x2))\n",
        "        null_distribution_new.append(D)\n",
        "    sns.distplot(np.array(null_distribution_new),label=\"std=%f\"%sigma_gene_new)\n",
        "plt.xlabel(\"D\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlTS65liI66r"
      },
      "source": [
        "The standard error of the difference between the means in the denominator of the T-statistic removes this dependency:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt-gejEQI66r"
      },
      "source": [
        "# a function to compute the T-statistic from two samples x1 and x2\n",
        "def compute_T_statistic(x1,x2):\n",
        "    sp = np.sqrt(((n-1)*np.var(x1)+(n-1)*np.var(x2))/float(n+n-2))\n",
        "    SE = sp * np.sqrt((1./n)+(1./n))\n",
        "    T_statistic = (np.mean(x1)-np.mean(x2))/SE\n",
        "    return T_statistic\n",
        "\n",
        "plt.figure(figsize=(5,5))    \n",
        "for sigma_gene_new in [0.01,0.03,0.06]:\n",
        "    null_distribution_new = []\n",
        "    for i in range(m):\n",
        "        x1 = np.random.normal(size=n,loc=0.26,scale=sigma_gene_new)\n",
        "        x2 = np.random.normal(size=n,loc=0.26,scale=sigma_gene_new)\n",
        "        null_distribution_new.append(compute_T_statistic(x1,x2)) #this is the only part that changed\n",
        "    sns.distplot(np.array(null_distribution),label=\"std=%f\"%sigma_gene_new)\n",
        "\n",
        "plt.xlabel(\"T\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuIyJfh7I66t"
      },
      "source": [
        "This leaves us with a null distribution for the T-statistic that depends only on $n_1$ and $n_2$ which is taken care of by the degrees of freedom for the Student’s t-distribution.\n",
        "\n",
        "Before we continue we a create the null distribution for samples sizes $n_1=n_2=9$ by repeadelty sampling $x_1$ and $x_2$ **from the same population**. Note that this null distribution does not depend on the mean $\\mu$ of the population."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FER8_3X1I66u"
      },
      "source": [
        "n = 9\n",
        "null_distribution = []\n",
        "for i in range(m):\n",
        "    x1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    x2 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    null_distribution.append(compute_T_statistic(x1,x2))\n",
        "plt.figure(figsize=(5,5))    \n",
        "sns.distplot(np.array(null_distribution),color=\"g\")\n",
        "plt.xlabel(\"T\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGRRNOmcI66x"
      },
      "source": [
        "Now, let's say we have two genes geneA and geneB and we want to know whether the mean expression level of these genes is the same. \n",
        "\n",
        "First we look at the case where the mean expression is indeed the same. We draw a sample for geneA and a sample for geneB with $n_A=n_B=9$ and compute the T-statistic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzdExRtVI66y"
      },
      "source": [
        "geneA = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "print(\"Mean geneA: %f\" % np.mean(geneA))\n",
        "geneB = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "print(\"Mean geneB: %f\" % np.mean(geneB))\n",
        "print(\"Mean difference: %f\" % (np.mean(geneA)-np.mean(geneB)))\n",
        "T_observed = compute_T_statistic(geneA,geneB)\n",
        "print(\"T-statistic: %f\" % T_observed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAdwjC0TI66z"
      },
      "source": [
        "Next we compute the corresponding p-value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi5LQY6dI660"
      },
      "source": [
        "print(\"p-value=%f\"%stats.ttest_ind(geneA,geneB)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTifJOcaI662"
      },
      "source": [
        "This is the p-value we obtain for our test. Again we need to set a significance level $\\alpha$ to decide on rejecting the null hypothesis and therefor accepting the alternative hypothesis.\n",
        "\n",
        "Now let's look at the case where geneB is sampled from a population with a different mean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta1XAqByI662"
      },
      "source": [
        "geneA = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "print(\"Mean geneA: %f\" % np.mean(geneA))\n",
        "geneB = np.random.normal(size=n,loc=0.275,scale=0.01)\n",
        "print(\"Mean geneB: %f\" % np.mean(geneB))\n",
        "print(\"Mean difference: %f\" % (np.mean(geneA)-np.mean(geneB)))\n",
        "T_observed = compute_T_statistic(geneA,geneB)\n",
        "print(\"T-statistic: %f\" % T_observed)\n",
        "print(\"p-value=%f\"%stats.ttest_ind(geneA,geneB)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iYmS2d7I665"
      },
      "source": [
        "As expected, this p-value is much smaller.\n",
        "\n",
        "It should be clear to you by now that different samples of geneA and geneB will produce different T-statistics and as such different p-values. So, **depending the sample sometimes we will correctly reject the null hypothesis and sometimes we will incorrectly accept it even though the samples are drawn from populations with different means**!\n",
        "\n",
        "Let's illustrate this by repeatedly drawing samples for geneA and geneB, computing the p-value and plotting these p-values as a boxplot: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv9WV9wDI665"
      },
      "source": [
        "pvalues = []\n",
        "for i in range(100):\n",
        "    geneA = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    geneB = np.random.normal(size=n,loc=0.275,scale=0.01)\n",
        "    pvalues.append(stats.ttest_ind(geneA,geneB).pvalue)\n",
        "df = pd.DataFrame()\n",
        "df[\"p-values\"] = pvalues\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.boxplot(df,showfliers=True)\n",
        "plt.axvline(x=0.01,c='r')\n",
        "plt.xlabel(\"p-value\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsS4kV5bI667"
      },
      "source": [
        "The red line corresponds to $\\alpha=0.01$. The boxplot shows that even though the mean expression level between geneA and geneB is not equal, in many cases the null hypothesis is incorrectly accepted ($\\alpha>0.01$). \n",
        "It just depends on the samples that were drawn, i.e. random chance.\n",
        "\n",
        "This brings us to the notion of **the power of a hypothesis test**. It is defined as the probability of correctly rejecting a false null hypothesis. To explain this we consider the situation where we increase the variance of the populations from which the samples are drawn while keeping the difference between the mean of the two populations and the sample sizes $n_1=n_2=n$ constant. \n",
        "\n",
        "The following boxplot shows the p-values obtained by repeatedly drawing samples for geneA and geneB from populations with increasing variance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JutU3txBI668"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "for sigma in [0.001,0.01,0.1]:\n",
        "    pvalues = []\n",
        "    for i in range(100):\n",
        "        geneA = np.random.normal(size=n,loc=0.26,scale=sigma)\n",
        "        geneB = np.random.normal(size=n,loc=0.27,scale=sigma)\n",
        "        pvalues.append(stats.ttest_ind(geneA,geneB).pvalue)\n",
        "    df[\"std=%f\"%sigma] = pvalues\n",
        "plt.figure(figsize=(5,5))\n",
        "df.boxplot()\n",
        "plt.title(\"p-values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOJNBxH9I669"
      },
      "source": [
        "The boxplots show how the p-values become larger for an increasing population variance.\n",
        "So the power of the two sample t-test decreases as the variance of the populations increases.\n",
        "\n",
        "Similarly, for a fixed difference in mean and a fixed variance of the populations we can look at the effect of an increasing sample sizes $n_1$ and $n_2$. We will look at the case where $n_1=n_2=n$: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGysRkTOI66-"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "for n_tmp in [6,9,12,18,32]:\n",
        "    pvalues = []\n",
        "    for i in range(100):\n",
        "        geneA = np.random.normal(size=n_tmp,loc=0.26,scale=0.01)\n",
        "        geneB = np.random.normal(size=n_tmp,loc=0.27,scale=0.01)\n",
        "        pvalues.append(stats.ttest_ind(geneA,geneB).pvalue)\n",
        "    df[\"n=%i\"%n_tmp] = pvalues\n",
        "plt.figure(figsize=(5,5))\n",
        "df.boxplot()\n",
        "plt.title(\"p-values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwfBI2g8c8d4"
      },
      "source": [
        "We can see that the power of the two sample t-test increase as the sample size increases. In fact, and this is important, **for increasingly larger sample sizes any difference between the means will become significant**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whDXRSXfc_J3"
      },
      "source": [
        "## The paired two sample t-test for equal means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49kPbdzmI66_"
      },
      "source": [
        "The paired two sample t-test for equal means is a hypothesis test that claims that the means of two samples $x_1$ with sample size $n$ and $x_2$ with sample size $n$ are equal for the case where observations in one sample can be paired with observations in the other sample.\n",
        "\n",
        "In this case the T-statistic that is used to test the null hypothesis is:\n",
        "\n",
        "$$T = \\frac{\\overline{d}}{SE(\\overline{d})},$$\n",
        "\n",
        "where $\\overline{d}$ is the mean difference between the paired observations and $SE(\\overline{d})$ is the standard error of the mean difference. It is computed as \n",
        "\n",
        "$$SE(\\overline{d}) = \\frac{s_d}{\\sqrt{n}},$$\n",
        "\n",
        "where $s_d$ is the standard deviation of the differences between the paired observations. This T-statistic follows a Student’s t-distribution with $n-1$ degrees of freedom.\n",
        "\n",
        "As an example consider measuring the expression level of geneA in $n=9$ randomly selected persons at two time points $t_1$ and $t_2$. The measurement at $t_1$ is a control measurement while $t_2$ is a measurement after taking a certain drug. We want to know if the drug has any effect on the expression level of geneA. We do this by comparing the mean expression level of geneA at $t_1$ with the mean expression level at $t_2$.   \n",
        "\n",
        "First, we consider the case where there is no difference in mean expression between $t_1$ and $t_2$. We draw two samples from the population of geneA expression levels and pair the observations at random, i.e. the pairing has no specific meaning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6v9ad7I66_"
      },
      "source": [
        "n = 9\n",
        "geneA_t1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "geneA_t2 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "# create DataFrame\n",
        "df = pd.DataFrame()\n",
        "df[\"geneA_t1\"] = geneA_t1\n",
        "df[\"geneA_t2\"] = geneA_t2\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq-zuWfVI67B"
      },
      "source": [
        "We consider each row in this dataset a paired observation (one person measured at two different time points). \n",
        "\n",
        "To make this more clear we can plot these observations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzp0RcgLI67B"
      },
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "df.boxplot()\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(np.zeros(len(geneA_t1)), geneA_t1)\n",
        "plt.scatter(np.ones(len(geneA_t2)), geneA_t2)\n",
        "for i in range(len(geneA_t1)):\n",
        "    plt.plot( [0,1], [geneA_t1[i], geneA_t2[i]], c='k')\n",
        "plt.xticks([0,1], ['geneA_t1', 'geneA_t2'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdR2mI7ZI67D"
      },
      "source": [
        "The plot on the right shows how the observations are paired. We have seen that we can perform an unpaired two sample t-test using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfvFLJnPI67D"
      },
      "source": [
        "stats.ttest_ind(geneA_t1,geneA_t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyGS9kv0I67F"
      },
      "source": [
        "The code to perform a paired two sample t-test is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P5JRksiI67F"
      },
      "source": [
        "stats.ttest_rel(geneA_t1,geneA_t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kmNTf5-I67I"
      },
      "source": [
        "We can see that both tests accept the null hypothesis for $\\alpha = 0.01$.\n",
        "Now let's again create paired observations but this time the expression level for the observation in $t_2$ is consistently higher as compared to the same observation in $t_1$: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZHMrslzI67I"
      },
      "source": [
        "geneA_t1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "geneA_t2 = geneA_t1 + np.random.normal(size=n,loc=0.005,scale=0.001) \n",
        "# create DataFrame\n",
        "df = pd.DataFrame()\n",
        "df[\"geneA_t1\"] = geneA_t1\n",
        "df[\"geneA_t2\"] = geneA_t2\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWWtUsEQI67K"
      },
      "source": [
        "We can again plot this dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RZI-C_iI67L"
      },
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "df.boxplot()\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(np.zeros(len(geneA_t1)), geneA_t1)\n",
        "plt.scatter(np.ones(len(geneA_t2)), geneA_t2)\n",
        "for i in range(len(geneA_t1)):\n",
        "    plt.plot( [0,1], [geneA_t1[i], geneA_t2[i]], c='k')\n",
        "plt.xticks([0,1], ['geneA_t1', 'geneA_t2'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOORyHcGI67M"
      },
      "source": [
        "We compare the unpaired and paired t-test gain:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJ_HZWEI67N"
      },
      "source": [
        "print(\"unpaired test: %f\" % stats.ttest_ind(geneA_t1,geneA_t2).pvalue)\n",
        "print(\"paired test: %f\" % stats.ttest_rel(geneA_t1,geneA_t2).pvalue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Pog55meqU8"
      },
      "source": [
        "Now we see a big diference between the p-values computed by both test. While the unpaired t-test does not conclude a difference in mean between $t_1$ and $t_2$, the paired t-test does. From the paired t-test we would conclude that the drug does have a consistent effect on the expression level of geneA, which is true.\n",
        "\n",
        "That means that **for paired observations the power of the paired t-test is much higher**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAOoly11esmM"
      },
      "source": [
        "## Non-parametric hypothesis tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTHuwHJhI67P"
      },
      "source": [
        "So far we have seen what we call **parametric hypothesis tests** that make assumptions about the shape of the population(s) from which the samples are drawn. In the tests we have discussed the distribution of the populations was assumed to be normal. \n",
        "\n",
        "However, many cases exist where this assumption cannot be made. In these cases a **non-parametric hypothesis test** that does not make such assumptions should be used to make inferences about the population. \n",
        "\n",
        "So, it there exists a non-parametric test then why use a parametric test? The answer is that the parametric test will have more statistical power, especially for small sample sizes.\n",
        "\n",
        "To illustrate this we compare the parametric two sample t-test with it's non-parametric alternative: the **Mann–Whitney U test** which tests for equality of the median of the samples.\n",
        "\n",
        "We draw 100 samples with size $n=4$ from two normal populations with different mean. We compute the p-value for the t-test and Mann-Whitney test for each pair of samples. \n",
        "\n",
        "From these 100 p-values we can compute the power for each test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVxZGAmFI67P"
      },
      "source": [
        "n = 4\n",
        "alpha = 0.01\n",
        "df = pd.DataFrame()\n",
        "pvalues = []\n",
        "tests = []\n",
        "correct_tt = 0\n",
        "correct_mw = 0\n",
        "for i in range(1000):\n",
        "    p1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "    p2 = np.random.normal(size=n,loc=0.28,scale=0.01)\n",
        "    pvalue = stats.ttest_ind(p1,p2).pvalue\n",
        "    pvalues.append(pvalue)\n",
        "    if pvalue <= alpha:\n",
        "        correct_tt+=1\n",
        "    tests.append(\"tt\")\n",
        "    pvalue = stats.mannwhitneyu(p1,p2,alternative=\"two-sided\").pvalue\n",
        "    pvalues.append(pvalue)\n",
        "    if pvalue <= alpha:\n",
        "        correct_mw+=1\n",
        "    tests.append(\"mw\")\n",
        "power_tt = correct_tt/1000.\n",
        "print(\"t-test power for n=%i: %.2f\" % (n,power_tt))\n",
        "power_mw = correct_mw/1000.\n",
        "print(\"Mann-Whitney power for n=%i: %.2f\" % (n,power_mw))\n",
        "df = pd.DataFrame()\n",
        "df[\"p-value\"] = pvalues\n",
        "df[\"test\"] = tests\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.boxplot(x=\"test\",y=\"p-value\",hue=\"test\",data=df,showfliers=False)\n",
        "plt.title(\"p-values\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLKWOc5eI67R"
      },
      "source": [
        "We can see that the two sample t-test has more power for normal distributions.\n",
        "\n",
        "Now we do the exact same thing but for increasing sample sizes $n$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpr51OECI67R"
      },
      "source": [
        "alpha = 0.01\n",
        "df = pd.DataFrame()\n",
        "pvalues = []\n",
        "ns = []\n",
        "tests = []\n",
        "for n in range(3,11,1):\n",
        "    correct_tt = 0\n",
        "    correct_mw = 0\n",
        "    for i in range(100):\n",
        "        p1 = np.random.normal(size=n,loc=0.26,scale=0.01)\n",
        "        p2 = np.random.normal(size=n,loc=0.28,scale=0.01)\n",
        "        pvalue = stats.ttest_ind(p1,p2).pvalue\n",
        "        pvalues.append(pvalue)\n",
        "        if pvalue <= alpha:\n",
        "            correct_tt+=1\n",
        "        tests.append(\"tt\")\n",
        "        ns.append(n)\n",
        "        pvalue = stats.mannwhitneyu(p1,p2,alternative=\"two-sided\").pvalue\n",
        "        pvalues.append(pvalue)\n",
        "        if pvalue <= alpha:\n",
        "            correct_mw+=1\n",
        "        tests.append(\"mw\")\n",
        "        ns.append(n)\n",
        "    power_tt = correct_tt/100.\n",
        "    print(\"t-test power for n=%i: %.2f\" % (n,power_tt))\n",
        "    power_mw = correct_mw/100.\n",
        "    print(\"Mann-Whitney power for n=%i: %.2f\" % (n,power_mw))\n",
        "df = pd.DataFrame()\n",
        "df[\"p-value\"] = pvalues\n",
        "df[\"test\"] = tests\n",
        "df[\"n\"] = ns\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.boxplot(x=\"n\",y=\"p-value\",hue=\"test\",data=df,showfliers=False)\n",
        "plt.title(\"p-values\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaIKdJXTI67T"
      },
      "source": [
        "We can see that the t-test consistently has more power for for sample sizes up to $n=10$. The difference in power between the test does however decrease fast for larger sample sizes."
      ]
    }
  ]
}